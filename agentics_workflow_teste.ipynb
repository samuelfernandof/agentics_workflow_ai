{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0HkbtIzMD9hH7qgxhbwXE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samuelfernandof/agentics_workflow_ai/blob/main/agentics_workflow_teste.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cqy8SJyMO16I"
      },
      "outputs": [],
      "source": [
        "# Inicializar SQLite para persistência do estado do grafo na memória.\n",
        "from langchain_core.savers import SqliteSaver\n",
        "\n",
        "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
        "\n",
        "# Definir o estado do agente como uma estrutura de dados com TypedDict\n",
        "from typing import List, TypedDict\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    task: str\n",
        "    plan: str\n",
        "    draft: str\n",
        "    critique: str\n",
        "    content: List[str]\n",
        "    sources: List[str]\n",
        "    revision_number: int\n",
        "    max_revisions: int"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir os prompts para cada estágio\n",
        "PLAN_PROMPT = \"\"\"Você é um especialista em criação de planos de negócios. Redija um esboço de alto nível sobre o tema fornecido pelo usuário. Incluir anotações e instruções relevantes.\"\"\"\n",
        "\n",
        "WRITER_PROMPT = \"\"\"Você é um assistente de relatórios profissionais. Gere o melhor relatório possível com base na solicitação do usuário e no esboço fornecido. Considere as críticas quando houver e utilize todas as informações abaixo:\n",
        "\n",
        "------\n",
        "{content}\n",
        "\n",
        "Fontes:\n",
        "{sources}\"\"\"\n",
        "\n",
        "REFLECTION_PROMPT = \"\"\"Você é um consultor sênior encarregado de revisar o relatório de negócios. Forneça recomendações detalhadas sobre o conteúdo, estilo e profundidade do texto, apontando melhorias claras.\"\"\"\n",
        "\n",
        "RESEARCH_PLAN_PROMPT = \"\"\"Você é um pesquisador responsável por obter dados para um relatório de negócios. Crie três consultas de pesquisa para coletar informações relevantes.\"\"\"\n",
        "\n",
        "RESEARCH_REVISOR_PROMPT = \"\"\"Você é um pesquisador que revisa as informações sugeridas. Crie até três consultas para melhorar as revisões solicitadas.\"\"\"\n",
        "\n",
        "DATA_ANALYSIS_PROMPT = \"\"\"Você é um assistente encarregado de extrair informações de documentos relacionados à tarefa fornecida. Concentre-se nos dados mais relevantes para a análise.\"\"\""
      ],
      "metadata": {
        "id": "qa9DTE2fPEY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar TavilyClient para busca avançada de informações\n",
        "from tavily import TavilyClient\n",
        "\n",
        "tavily = TavilyClient(api_key=\"sua-chave\")"
      ],
      "metadata": {
        "id": "bJWC_EiSPJCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_core.models import SystemMessage, HumanMessage\n",
        "\n",
        "# Função para ler documentos de uma pasta específica\n",
        "def read_documents_from_folder(folder_path):\n",
        "    documents = []\n",
        "    sources = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(\".md\"):  # Extensão de arquivo, pode ser ajustada para outros formatos\n",
        "            with open(os.path.join(folder_path, filename), 'r') as file:\n",
        "                documents.append(file.read())\n",
        "                sources.append(filename)\n",
        "    return documents, sources\n",
        "\n",
        "# Nó de planejamento\n",
        "def plan_node(state: AgentState):\n",
        "    messages = [\n",
        "        SystemMessage(content=PLAN_PROMPT),\n",
        "        HumanMessage(content=state['task'])\n",
        "    ]\n",
        "    response = model.invoke(messages)\n",
        "    return {\"plan\": response.content}\n",
        "\n",
        "# Nó de pesquisa para coletar informações\n",
        "def research_plan_node(state: AgentState):\n",
        "    queries = model.with_structured_output(Queries).invoke([\n",
        "        SystemMessage(content=RESEARCH_PLAN_PROMPT),\n",
        "        HumanMessage(content=state['task'])\n",
        "    ])\n",
        "    content = state.get('content', [])\n",
        "    sources = state.get('sources', [])\n",
        "\n",
        "    # Utilizar Tavily para pesquisar\n",
        "    for query in queries.queries:\n",
        "        response = tavily.search(query=query, max_results=3)  # Melhoria: 3 resultados por query\n",
        "        for r in response['results']:\n",
        "            content.append(r['content'])\n",
        "            sources.append(r.get('source', 'Fonte desconhecida'))\n",
        "\n",
        "    return {\"content\": content, \"sources\": sources}\n",
        "\n",
        "# Nó para análise de documentos internos\n",
        "def document_analysis_node(state: AgentState):\n",
        "    folder_path = \"company_docs\"  # Pasta onde os documentos da empresa estão armazenados\n",
        "    documents, sources = read_documents_from_folder(folder_path)\n",
        "\n",
        "    content = state.get('content', [])\n",
        "    for document in documents:\n",
        "        messages = [\n",
        "            SystemMessage(content=DOCUMENT_ANALYSIS_PROMPT),\n",
        "            HumanMessage(content=document)\n",
        "        ]\n",
        "        response = model.invoke(messages)\n",
        "        content.append(response.content)\n",
        "\n",
        "    # Atualizar as fontes\n",
        "    all_sources = state.get('sources', [])\n",
        "    all_sources.extend(sources)\n",
        "\n",
        "    return {\"content\": content, \"sources\": all_sources}\n",
        "\n",
        "# Nó de geração de rascunho\n",
        "def generation_node(state: AgentState):\n",
        "    content = \"\\n\\n\".join(state.get('content', []))\n",
        "    sources = \"\\n\".join(state.get('sources', []))\n",
        "    user_message = HumanMessage(content=f\"{state['task']}\\n\\nAqui está o plano:\\n\\n{state['plan']}\")\n",
        "\n",
        "    messages = [\n",
        "        SystemMessage(content=WRITER_PROMPT.format(content=content, sources=sources)),\n",
        "        user_message\n",
        "    ]\n",
        "    response = model.invoke(messages)\n",
        "\n",
        "    return {\n",
        "        \"draft\": response.content,\n",
        "        \"revision_number\": state.get(\"revision_number\", 1) + 1\n",
        "    }\n",
        "\n",
        "# Nó de reflexão e crítica\n",
        "def reflection_node(state: AgentState):\n",
        "    messages = [\n",
        "        SystemMessage(content=REFLECTION_PROMPT),\n",
        "        HumanMessage(content=state['draft'])\n",
        "    ]\n",
        "    response = model.invoke(messages)\n",
        "    return {\"critique\": response.content}\n",
        "\n",
        "# Nó de pesquisa com base nas críticas\n",
        "def research_critique_node(state: AgentState):\n",
        "    queries = model.with_structured_output(Queries).invoke([\n",
        "        SystemMessage(content=RESEARCH_CRITIQUE_PROMPT),\n",
        "        HumanMessage(content=state['critique'])\n",
        "    ])\n",
        "    content = state.get('content', [])\n",
        "    sources = state.get('sources', [])\n",
        "\n",
        "    # Pesquisar as críticas\n",
        "    for query in queries.queries:\n",
        "        response = tavily.search(query=query, max_results=3)\n",
        "        for r in response['results']:\n",
        "            content.append(r['content'])\n",
        "            sources.append(r.get('source', 'Fonte desconhecida'))\n",
        "\n",
        "    return {\"content\": content, \"sources\": sources}\n",
        "\n",
        "# Verificação para continuar ou parar\n",
        "def should_continue(state):\n",
        "    if state[\"revision_number\"] > state[\"max_revisions\"]:\n",
        "        return \"END\"\n",
        "    return \"reflect\""
      ],
      "metadata": {
        "id": "zefDdXd9PLmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.graph import StateGraph\n",
        "\n",
        "# Criar o gráfico de estados\n",
        "builder = StateGraph(AgentState)\n",
        "\n",
        "builder.add_node(\"plan\", plan_node)\n",
        "builder.add_node(\"generate\", generation_node)\n",
        "builder.add_node(\"reflect\", reflection_node)\n",
        "builder.add_node(\"research_plan\", research_plan_node)\n",
        "builder.add_node(\"document_analysis\", document_analysis_node)\n",
        "builder.add_node(\"research_critique\", research_critique_node)\n",
        "\n",
        "builder.set_entry_point(\"plan\")\n",
        "builder.add_conditional_edges(\n",
        "    \"generate\",\n",
        "    should_continue,\n",
        "    {\"END\": \"END\", \"reflect\": \"reflect\"}\n",
        ")\n",
        "\n",
        "builder.add_edge(\"plan\", \"research_plan\")\n",
        "builder.add_edge(\"research_plan\", \"document_analysis\")\n",
        "builder.add_edge(\"document_analysis\", \"generate\")\n",
        "builder.add_edge(\"reflect\", \"research_critique\")\n",
        "builder.add_edge(\"research_critique\", \"generate\")\n",
        "\n",
        "graph = builder.compile(checkpointer=memory)\n",
        "\n",
        "#Visualizar grafo\n",
        "from IPython.display import Image\n",
        "\n",
        "# Exibir o grafo\n",
        "Image(graph.get_graph().draw_png())"
      ],
      "metadata": {
        "id": "lIZltsN7PRLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir o estado inicial e iniciar o gráfico\n",
        "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "# Definir a tarefa inicial do agente\n",
        "initial_state = {\n",
        "    'task': \"A Take-it-easy Inc. está enfrentando uma queda nas vendas de sua principal linha de produtos, que está no mercado há 10 anos. Eles suspeitam de aumento da concorrência e estratégias de marketing desatualizadas. O resultado desejado é revitalizar as vendas e recuperar a participação de mercado nos próximos 6 meses. Eles estão abertos a explorar novos canais de marketing. Gere um relatório de exemplo de 2 páginas em formato markdown, com um teaser de possíveis soluções e como a LN Consulting pode ajudar, listando estudos de caso relevantes, links de pesquisa, e nomes de documentos.\",\n",
        "    \"max_revisions\": 2,  # Número máximo de revisões\n",
        "    \"revision_number\": 1  # Começar da primeira revisão\n",
        "}\n",
        "\n",
        "# Executar o gráfico com base no estado inicial\n",
        "for s in graph.stream(initial_state, thread):\n",
        "    print(s)\n",
        "\n",
        "from langtrace_python_sdk import langtrace\n",
        "\n",
        "# Inicializar rastreamento com LangTrace\n",
        "langtrace.init(api_key='sua_chave')\n",
        "\n",
        "# Adicione rastreamento ao gráfico\n",
        "for s in graph.stream(initial_state, thread):\n",
        "    langtrace.record_state(s)\n",
        "    print(s)"
      ],
      "metadata": {
        "id": "Zw7FXLrBPVOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WuMB_22DPYPx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}